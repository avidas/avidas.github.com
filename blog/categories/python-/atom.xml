<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python, | Avi Das]]></title>
  <link href="http://avidas.github.com/blog/categories/python-/atom.xml" rel="self"/>
  <link href="http://avidas.github.com/"/>
  <updated>2015-07-03T15:46:01-05:00</updated>
  <id>http://avidas.github.com/</id>
  <author>
    <name><![CDATA[Avi (Ananya Das)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Verifying X509 Certificate Chain of Trust in Python]]></title>
    <link href="http://avidas.github.com/blog/2015/06/18/verifying-x509-certificate-chain-of-trust-in-python/"/>
    <updated>2015-06-18T17:07:00-05:00</updated>
    <id>http://avidas.github.com/blog/2015/06/18/verifying-x509-certificate-chain-of-trust-in-python</id>
    <content type="html"><![CDATA[<p>Executing network spoofing and man in the middle attacks have become easier than ever. This is more of an issue if a client has an open server for you to send push notifications, since the open port can be detected by methods such as port scanning. As such, it is important to sign data, and ship the signature and metadata about verifying the data against the signature along with the data itself. This provides a way for the client to verify that the data received is unaltered, from the correct sender and indented for the correct recipient. Python's pyopenssl has a handy method called <a href="http://pyopenssl.readthedocs.org/en/latest/api/crypto.html?highlight=verify#OpenSSL.crypto.verify">verify</a> for checking the authenticity of data.</p>

<p><code>python
OpenSSL.crypto.verify(certificate, signature, data, digest)
</code></p>

<p>The problem then becomes how to provide the certificate while retaining the flexibility necessary to update the certificate without clients needing to modify their certificate stores every time. Providing a url that can be used to download the cert provides that but leaves the door open for the same kind of attacks.</p>

<p>Therefore, clients will need to ensure that the downloaded certificate is trustworthy before using it to verify the authenticity of a message. The openssl module on the terminal has a <a href="https://www.openssl.org/docs/apps/verify.html">verify method</a> that can be used to verify the certificate against a chain of trusted certificates, going all the way back to the root CA. The builtin ssl module has create_default_context(), which can build a certificate chain while creating a new SSLContext. However, it does not expose that functionality for adhoc post processing when you are not opening new connections.</p>

<p>pyopenssl provides some very handy abstractions for exactly this purpose:</p>

<ul>
<li><p><a href="http://pyopenssl.readthedocs.org/en/latest/api/crypto.html#x509store-objects">X509Store</a>: The chain of certificates you have chosen to trust going back to root Certificate Authority</p></li>
<li><p><a href="http://pyopenssl.readthedocs.org/en/latest/api/crypto.html#x509storecontext-objects">X509StoreContext</a> - Takes in a X509Store and a new certificate which you can now validate against your store by calling verify_certificate. It raises exceptions if the intermediate or root CA is missing in the chain or the certificate is invalid.</p></li>
</ul>


<p> The full example of verifying a downloaded certificate against a trust chain is given below</p>

<p>```python
import requests
from OpenSSL import crypto</p>

<p>def _verify_certificate_chain(cert_url, trusted_certs):</p>

<pre><code># Download the certificate from the url and load the certificate
cert_str = requests.get(cert_url)
certificate = crypto.load_certificate(crypto.FILETYPE_PEM, str(cert_str.text))

#Create a certificate store and add your trusted certs
try:
    store = crypto.X509Store()

    # Assuming the certificates are in PEM format in a trusted_certs list
    for _cert in trusted_certs:
        store.add_cert(_cert)

    # Create a certificate context using the store and the downloaded certificate
    store_ctx = crypto.X509StoreContext(store, certificate)

    # Verify the certificate, returns None if it can validate the certificate
    store_ctx.verify_certificate()

    return True

except Exception as e:
    print(e)
    return False
</code></pre>

<p>```</p>

<p>Using this can be really useful for client libaries where you cannot rely on the system to provide the certificates, so you can ship your trust chain along with the library. There are also other useful abstractions in the pyopenssl library for some useful checks against the certificate. get_subject() provides information about the certificate such as common name, has_expired() which checks if the certificate is within valid time range and other features such as blacklisting potentially compromised certificates are possible. Thus pyopenssl is really handy when you need ssl abstractions beyond the standard library while not needing to execute the openssl shell calls via a subprocess.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scipy 2014: Python as expression to push boundaries in science]]></title>
    <link href="http://avidas.github.com/blog/2014/07/13/scipy-2014-python-as-expression-to-push-boundaries-in-science/"/>
    <updated>2014-07-13T20:22:00-05:00</updated>
    <id>http://avidas.github.com/blog/2014/07/13/scipy-2014-python-as-expression-to-push-boundaries-in-science</id>
    <content type="html"><![CDATA[<p>It's not everyday that the person sitting next to you interacts with Mars Rovers everyday or is trying to build a data pipeline to handle petabyte-scale genomics data. But that was perhaps the key takeway from my first <a href="https://conference.scipy.org/scipy2014/">Python conference</a>: a large number of people pushing the boundaries in scientific disciplines and using Python as their means of expression.</p>

<p>I have been using Python for a while now, both at work and for hobby projects but until of late have mostly been in the peripheries in contributions to open source projects. When I learned about Scientific Python conference right near to me in Austin, I was immediately interested. If you buy that there is such a thing as language wars, scientific computing has been one of Python's key wins. With libraries such as NumPy, Matplotlib and Pandas (and of course IPython), Python have dominated the Scientific Python landscape alongside R and Julia.</p>

<p>When such a strong ecosystem is matched by a very welcoming community, there is a recipe for a conference worth being at. Well, If you can get past the imposter syndrome of being at a place with the highest density of phds of any place I have ever been at.</p>

<h3>Takeaways</h3>

<ol>
<li><p><strong>Python catching up in areas where it lacked</strong>:
Performance, distribution, scalibility and reproducability were some of main themes at the conference. This addresses some of the historic lackings of the language. Sometimes this is via adoption of new tools such as docker for containerizing work enviroments for remote co-working researchers. Dependency on other languages has been one of the major pain points in working with the scientific Python libraries, so it is great to see Conda and HashDist (which I just discovered) to take that head on. Interoperability and scalability are two of the main problems Blaze is solving, and Bokeh and Plotly takes on the problems of publishing and sharing interactive visualizations in Python.</p></li>
<li><p><strong> New tools for my workflow</strong>:
There are many tools which deserve a space here, but I was primarily exited to discover pyspark, yt, plotly, sumatra/vistrails, hashdist and airspeed velocity. Version control and workflow control are familiar terratories for software engineers, but the idea of event control was new to me, something explored in a Birds of a feather discussion.</p></li>
<li><p><strong>Birds of a Feather talks are revealing</strong>:
Birds of a feather discussions were sometimes my favorite, where there was candid sharing of painpoints and their solutions from the community members. It was also good to know what were the open problems in various areas are as they often indicate valuable areas to focus on.</p></li>
</ol>


<!-- more -->


<ol>
<li><p><strong>Contributions are needed</strong>:
It was great to see a lot of egoless collaboration during the conference. Maintainers of projects were willing to deprecate their hard work in favor of a better accepted tool in the community. At the same time, lot of the development of very instrumental tools seem to be done by a small group of people, highlighting the need for more collaborators in this space.</p></li>
<li><p><strong>Sprints are like speed dating for open source projects</strong>:
SciPy sprints were very different environment from hackathons. With the removal of prize as a factor, what remains is people who enjoy their work and often are highly productive. With the large number of projects available and the acceptance by the core developers, I had the opportunity to work on the charting library Bokeh, serialization library Dill, hack on datasets with yt developers (because random access over a 32 TB file served by apache to generate a graph on Ipython fully client side is seriously impressive) and dig into dockerizing web apps and databases with the reproducable workflow group. All in two days work.</p></li>
</ol>


<p>As someone who is primarily an app developer, this conference was challenging as I have diverged from the path of scientific research a while back. Despite that, I have came away with a strong appreciation for the scientific python community and ecosystem and must thank PayPal for letting me attend the confrence.</p>

<p>To finish, the keynote on the third day by Greg Wilson was quite fantastic and you should check it out if you haven't already:</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/1e26rp6qPbA" allowfullscreen></iframe></div></p>
]]></content>
  </entry>
  
</feed>
