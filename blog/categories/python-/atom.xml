<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python, | Avi Das]]></title>
  <link href="http://avidas.github.com/blog/categories/python-/atom.xml" rel="self"/>
  <link href="http://avidas.github.com/"/>
  <updated>2015-09-13T23:13:24-05:00</updated>
  <id>http://avidas.github.com/</id>
  <author>
    <name><![CDATA[Avi (Ananya Das)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Evaluating React.js and Flask]]></title>
    <link href="http://avidas.github.com/blog/2015/08/05/evaluating-react-dot-js-and-flask/"/>
    <updated>2015-08-05T10:39:00-05:00</updated>
    <id>http://avidas.github.com/blog/2015/08/05/evaluating-react-dot-js-and-flask</id>
    <content type="html"><![CDATA[<p>As a connoisseur of the web, front end frameworks have been been a fertile area of late. React.js from Facebook has taken much fanfare, and this post evaluates key ideas on react, and digs into why you could be interested in React. Staying true to single responsibility principle, React is a highly useful tool to have if you are doing web programming.</p>

<p>In this post, we will dive into how you can use a Frontend built using React.js and Backend built using the Python framework Flask. Flask is a minimalistic framework, and excellent when your backend becomes more and more of an API. Moreover, this facilitates the microservices architecture, where the decoupling of your your app into small unit of services can make it more maintainable and scalable.</p>

<p>We will cover some of the key ideas of React and Flask here, but it would be worth referring to the official documentation for <a href="https://facebook.github.io/react/">React</a> and <a href="http://flask.pocoo.org/">Flask</a> for getting started and understanding the philosophies of each framework.</p>

<h3>Key Ideas of React</h3>

<p>The core idea of React is the developers are better of leaving manipulating the DOM to battle tested framework code. Since the DOM has a tree structure, finding elements and manipulating them would need many traversals of a potentially very large tree.  Instead, what you modify is a virtual DOM, and React runs its intelligent diff algorithm to directly update the DOM.</p>

<h5>React</h5>

<p>React itself is the UI library that will manage all the DOM updates as data changes. It's takes the V of MVC frameworks, hence it can be used with other MVC frameworks such as Angular or Backbone.js. It is quite easy to use React to manage specific areas of your application's UI, rather than the entire app.</p>

<h5>Virtual Dom</h5>

<p>The virtual Dom is an abstraction layer between nodes in the real DOM and the view of the code you are modifying. When React selectively renders subtrees of the nodes in DOM based upon state changes, it achieves the following</p>

<pre><code> 1. Ensures that your DOM is always up to date with current state
 2. Reduces the need to re-render the DOM every time there is change in state
 3. Updating only the individual components on state change ensures high performance
</code></pre>

<h5>JSX</h5>

<p>JSX is a JavaScript syntax extension and it brings in a HTML/XML like familiar syntax for defining a tree structure with attributes. This is the syntax you can use to declare the changes in layout code and React will update the UI. It's a bold approach, since developers are conditioned to keep layout code separate from Javascript. We will explain more React terminology later as we dive into some code.</p>

<h3>Key Ideas of Flask</h3>

<p>Flask is a microframework, which means that it trades a short learning curve for fewer out of the box functionalities, compared to heavier frameworks such as Django or Rails. It gives developers more freedom to use their preferable tools and libraries. However, it does have a list of officially supported <a href="http://flask.pocoo.org/extensions/">extensions</a> which when plugged in provide a wide breath of functionalities for a standard web app. Extensions behave as if they are native flask code.</p>

<p>We strongly recommend that you set up a <a href="http://www.virtualenv.org/">virtualenv</a> for this project, and you may also want to check out <a href="http://virtualenvwrapper.readthedocs.org/">virtualenvwrapper</a> for convenience. This is to provide your app with a sandboxed environment.</p>

<h5>Getting up and running with Flask</h5>

<p>Lets first install Flask</p>

<p>```bash
pip install Flask</p>

<h1>For viewing and reusing app dependencies</h1>

<p>pip freeze > requirements.txt
```
Set up the following directory structure in your app.</p>

<p>```bash</p>

<p>├── README.md
├── app.py
├── requirements.txt
└── templates</p>

<pre><code>└── index.html
</code></pre>

<p>```</p>

<p>Modify your app.py code to include the following</p>

<p>```python
from flask import Flask, render_template</p>

<p>app = Flask(<strong>name</strong>)</p>

<p>@app.route("/")</p>

<p>def index():</p>

<pre><code>return render_template('index.html')
</code></pre>

<p>if <strong>name</strong> == "<strong>main</strong>":</p>

<pre><code>app.run()
</code></pre>

<p>```</p>

<p>We start by importing Flask and creating a new instance of a flask application. In flask, app.route is used to describe the behavior when users hit particular endpoints in the application. Here when user hits the index route, we render a template called hello world. By default Flask uses the Jinja2 templating language, but you can use any other templating language. In fact, we will not be covering Jinja2 in this blog post. Finally we tell python to call the run method of the app when invoked as a main function.</p>

<p>Let's populate index.html with the following basic HTML boilerplate</p>

<p>```html</p>

<p>&lt;!DOCTYPE html>
<html lang="en">
<head></p>

<pre><code>&lt;meta charset="UTF-8"&gt;
&lt;title&gt;Flask React Tutorial&lt;/title&gt;
</code></pre>

<p></head>
<body></p>

<pre><code> &lt;div id="mount-point"&gt;
     &lt;p1&gt;Hello world.&lt;/p1&gt;
 &lt;/div&gt;
</code></pre>

<p></body>
</html>
```</p>

<p>Now run the app with</p>

<p><code>bash
python app.py
// * Running on http://127.0.0.0:5000/
// * Restarting with reloader
</code>
By default it runs on port 5000. Navigate to the endpoint and you should see the html page you just created. You are now up and running with Flask!</p>

<h5>Integrate React</h5>

<p>Easiest way to include React would be to just include them from a cdn. Let's update the index.html to include React and and port our existing html to React. index.html will now look like</p>

<p>```html</p>

<p>&lt;!DOCTYPE html>
<html lang="en">
<head></p>

<pre><code>&lt;meta charset="UTF-8"&gt;
&lt;title&gt;Flask React Tutorial&lt;/title&gt;
&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/react/0.13.2/react.min.js"&gt;&lt;/script&gt;
&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/react/0.13.2/JSXTransformer.js"&gt;
</code></pre>

<p></head>
<body></p>

<pre><code> &lt;div id="mount-point"&gt;&lt;/div&gt;
</code></pre>

<p></body></p>

<p>  <script type="text/jsx"></p>

<pre><code> /*** @jsx React.DOM */
var FirstComponent = React.createClass({
    render: function() {
        return (&lt;p1&gt;Hello world.&lt;/p1&gt;);
    }
});
React.render(&lt;FirstComponent /&gt;, document.getElementById('mount-point') );
 &lt;/script&gt;
</code></pre>

<p></html>
```</p>

<p>Let's go over the code. We first include the react and jsx libraries via the script tags and remove the earlier p tags. We set up a jsx script by specifying type="text/jsx". Then we call createClass method of React which creates a React component. React components are reusable units that you can use to compose your UI. The component must have at least the render method, which returns the virtual representation of a native DOM element or another component.
Next we call React.render with the first element and pass it the id of the div element on which we want the result of the render function to be. Run the app again to navigate to the same path to see the app again.</p>

<h5>Data binding with React</h5>

<p>For a more practical example, as well to demonstrate multiple components, let's produce a type along data binding example. You can replace your script tag with the following</p>

<p>```html</p>

<script type="text/jsx">
    /** @jsx React.DOM */
    var Input = React.createClass({
        updateLabel: function(event){
            this.setState({value: event.target.value});
        },
        getInitialState: function(){
            return {
                value: ''
            }
        },
        componentWillMount: function(){
            this.setState({value: this.state.value})
        },
        render: function(){
            return (
                <div className="update-label">
                      <input type="text" placeholder="Enter text" onChange={this.updateLabel}/>
                    <Label value={this.state.value}/>
                </div>
        )
    }
});

var Label = React.createClass({
    render: function(){
        return (
        <div class="my-label">
        <h2>{this.props.value}</h2>
        </div>
        )
    }
});

React.render(<Input/>, document.getElementById('mount-point'));
</script>


<p>```</p>

<p>As before, React.render is called at the very end on a component called Input and it is bound to the element with id mount-point. Inside the Input component a few other lifecycle functions are introduced.</p>

<p>The method getInitialState is called once before the component mounts and  responsible for setting for the initial state of a component.
componentWillMount is called directly before a react component is initially rendered. Inside componentWillMount, we invoke setState.</p>

<p>setState can trigger UI updates from event handlers and server request callbacks. It will always cause a re-render to happen. Once render is called, it returns a div with a input box and a React component called label. We attach the method updateLabel which gets invoked when the text inside the input box changes. It updates this.state.value.</p>

<p>State attributes are mutable within a component and are used to represent the interaction changes changes within a component. On the other hand, props are immutable and used to pass data from a parent component to a child. In this case Label is a child component of Input, and this.state.value for Input is passed to Label, which can access it by this.props.value. Thus Input passes the data entered into the input box to Label and causes it to re-render and display the text.</p>

<p>Fire up the server again and type something into the input box and the content gets updated in the h2 element underneath.</p>

<h5>Why React</h5>

<p>As it turns out, the selling points of React are not super hard to get and clear use cases became obvious.</p>

<ol>
<li><p>React is very efficient in the way it handles DOM updates. It is important however, to isolate that heavy rendering or interactions are the bottlenecks so that you are not optimizing prematurely and likely already have optimized database interactions and network calls.</p></li>
<li><p>SEO management overhead can be less with React compared to Angular/Ember since it can be rendered server side. The benefit comes from not having the overhead of rendering your page server side with something like PhantomJS and serving the HTML.</p></li>
<li><p>Reusable components make the code more reusable and testable, and the short terminology keeps the learning curve managable.</p></li>
<li><p>Since React can be rendered Server Side, you might completely get rid of your server side templating, further reducing the number of tools necessary to run your app.</p></li>
</ol>


<!-- more -->


<h5>React and Flask</h5>

<p>With their focus on SRP, React and Flask could be dependable and efficient parts of your stack. This is specially handy if you want to leverage the Numpy/Scipy stack for doing data analysis in near realtime and serve up a frontend with heavy user interaction. In a later post, we will look at exploring interactive applications and introduce Socket.io.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Verifying X509 Certificate Chain of Trust in Python]]></title>
    <link href="http://avidas.github.com/blog/2015/06/18/verifying-x509-certificate-chain-of-trust-in-python/"/>
    <updated>2015-06-18T17:07:00-05:00</updated>
    <id>http://avidas.github.com/blog/2015/06/18/verifying-x509-certificate-chain-of-trust-in-python</id>
    <content type="html"><![CDATA[<p>Executing network spoofing and man in the middle attacks have become easier than ever. This is more of an issue if a client has an open server for you to send push notifications, since the open port can be detected by methods such as port scanning. As such, it is important to sign data, and ship the signature and metadata about verifying the data against the signature along with the data itself. This provides a way for the client to verify that the data received is unaltered, from the correct sender and indented for the correct recipient. Python's pyopenssl has a handy method called <a href="http://pyopenssl.readthedocs.org/en/latest/api/crypto.html?highlight=verify#OpenSSL.crypto.verify">verify</a> for checking the authenticity of data.</p>

<p><code>python
OpenSSL.crypto.verify(certificate, signature, data, digest)
</code></p>

<p>The problem then becomes how to provide the certificate while retaining the flexibility necessary to update the certificate without clients needing to modify their certificate stores every time. Providing a url that can be used to download the cert provides that but leaves the door open for the same kind of attacks.</p>

<p>Therefore, clients will need to ensure that the downloaded certificate is trustworthy before using it to verify the authenticity of a message. The openssl module on the terminal has a <a href="https://www.openssl.org/docs/apps/verify.html">verify method</a> that can be used to verify the certificate against a chain of trusted certificates, going all the way back to the root CA. The builtin ssl module has create_default_context(), which can build a certificate chain while creating a new SSLContext. However, it does not expose that functionality for adhoc post processing when you are not opening new connections.</p>

<p>pyopenssl provides some very handy abstractions for exactly this purpose:</p>

<ul>
<li><p><a href="http://pyopenssl.readthedocs.org/en/latest/api/crypto.html#x509store-objects">X509Store</a>: The chain of certificates you have chosen to trust going back to root Certificate Authority</p></li>
<li><p><a href="http://pyopenssl.readthedocs.org/en/latest/api/crypto.html#x509storecontext-objects">X509StoreContext</a> - Takes in a X509Store and a new certificate which you can now validate against your store by calling verify_certificate. It raises exceptions if the intermediate or root CA is missing in the chain or the certificate is invalid.</p></li>
</ul>


<p> The full example of verifying a downloaded certificate against a trust chain is given below</p>

<p>```python
import requests
from OpenSSL import crypto</p>

<p>def _verify_certificate_chain(cert_url, trusted_certs):</p>

<pre><code># Download the certificate from the url and load the certificate
cert_str = requests.get(cert_url)
certificate = crypto.load_certificate(crypto.FILETYPE_PEM, str(cert_str.text))

#Create a certificate store and add your trusted certs
try:
    store = crypto.X509Store()

    # Assuming the certificates are in PEM format in a trusted_certs list
    for _cert in trusted_certs:
        store.add_cert(_cert)

    # Create a certificate context using the store and the downloaded certificate
    store_ctx = crypto.X509StoreContext(store, certificate)

    # Verify the certificate, returns None if it can validate the certificate
    store_ctx.verify_certificate()

    return True

except Exception as e:
    print(e)
    return False
</code></pre>

<p>```</p>

<p>Using this can be really useful for client libaries where you cannot rely on the system to provide the certificates, so you can ship your trust chain along with the library. There are also other useful abstractions in the pyopenssl library for some useful checks against the certificate. get_subject() provides information about the certificate such as common name, has_expired() which checks if the certificate is within valid time range and other features such as blacklisting potentially compromised certificates are possible. Thus pyopenssl is really handy when you need ssl abstractions beyond the standard library while not needing to execute the openssl shell calls via a subprocess.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scipy 2014: Python as expression to push boundaries in science]]></title>
    <link href="http://avidas.github.com/blog/2014/07/13/scipy-2014-python-as-expression-to-push-boundaries-in-science/"/>
    <updated>2014-07-13T20:22:00-05:00</updated>
    <id>http://avidas.github.com/blog/2014/07/13/scipy-2014-python-as-expression-to-push-boundaries-in-science</id>
    <content type="html"><![CDATA[<p>It's not everyday that the person sitting next to you interacts with Mars Rovers everyday or is trying to build a data pipeline to handle petabyte-scale genomics data. But that was perhaps the key takeway from my first <a href="https://conference.scipy.org/scipy2014/">Python conference</a>: a large number of people pushing the boundaries in scientific disciplines and using Python as their means of expression.</p>

<p>I have been using Python for a while now, both at work and for hobby projects but until of late have mostly been in the peripheries in contributions to open source projects. When I learned about Scientific Python conference right near to me in Austin, I was immediately interested. If you buy that there is such a thing as language wars, scientific computing has been one of Python's key wins. With libraries such as NumPy, Matplotlib and Pandas (and of course IPython), Python have dominated the Scientific Python landscape alongside R and Julia.</p>

<p>When such a strong ecosystem is matched by a very welcoming community, there is a recipe for a conference worth being at. Well, If you can get past the imposter syndrome of being at a place with the highest density of phds of any place I have ever been at.</p>

<h3>Takeaways</h3>

<ol>
<li><p><strong>Python catching up in areas where it lacked</strong>:
Performance, distribution, scalibility and reproducability were some of main themes at the conference. This addresses some of the historic lackings of the language. Sometimes this is via adoption of new tools such as docker for containerizing work enviroments for remote co-working researchers. Dependency on other languages has been one of the major pain points in working with the scientific Python libraries, so it is great to see Conda and HashDist (which I just discovered) to take that head on. Interoperability and scalability are two of the main problems Blaze is solving, and Bokeh and Plotly takes on the problems of publishing and sharing interactive visualizations in Python.</p></li>
<li><p><strong> New tools for my workflow</strong>:
There are many tools which deserve a space here, but I was primarily exited to discover pyspark, yt, plotly, sumatra/vistrails, hashdist and airspeed velocity. Version control and workflow control are familiar terratories for software engineers, but the idea of event control was new to me, something explored in a Birds of a feather discussion.</p></li>
<li><p><strong>Birds of a Feather talks are revealing</strong>:
Birds of a feather discussions were sometimes my favorite, where there was candid sharing of painpoints and their solutions from the community members. It was also good to know what were the open problems in various areas are as they often indicate valuable areas to focus on.</p></li>
</ol>


<!-- more -->


<ol>
<li><p><strong>Contributions are needed</strong>:
It was great to see a lot of egoless collaboration during the conference. Maintainers of projects were willing to deprecate their hard work in favor of a better accepted tool in the community. At the same time, lot of the development of very instrumental tools seem to be done by a small group of people, highlighting the need for more collaborators in this space.</p></li>
<li><p><strong>Sprints are like speed dating for open source projects</strong>:
SciPy sprints were very different environment from hackathons. With the removal of prize as a factor, what remains is people who enjoy their work and often are highly productive. With the large number of projects available and the acceptance by the core developers, I had the opportunity to work on the charting library Bokeh, serialization library Dill, hack on datasets with yt developers (because random access over a 32 TB file served by apache to generate a graph on Ipython fully client side is seriously impressive) and dig into dockerizing web apps and databases with the reproducable workflow group. All in two days work.</p></li>
</ol>


<p>As someone who is primarily an app developer, this conference was challenging as I have diverged from the path of scientific research a while back. Despite that, I have came away with a strong appreciation for the scientific python community and ecosystem and must thank PayPal for letting me attend the confrence.</p>

<p>To finish, the keynote on the third day by Greg Wilson was quite fantastic and you should check it out if you haven't already:</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/1e26rp6qPbA" allowfullscreen></iframe></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prioritized date interval merge]]></title>
    <link href="http://avidas.github.com/blog/2013/08/30/prioritized-date-interval-merge/"/>
    <updated>2013-08-30T23:57:00-05:00</updated>
    <id>http://avidas.github.com/blog/2013/08/30/prioritized-date-interval-merge</id>
    <content type="html"><![CDATA[<p>Ran into this interesting problem lately and wanted to code up a recursive solution in Python. Essentially an extension of merge from merge sort but for intervals. There is definitely something very satisfying about coding up a recursive solution, as they tend to produce clean solutions despite the ugly formatting in this case to make list concatenation work.</p>

<p>``` python Merge date intervals by priority https://github.com/avidas/Code_snippets/blob/master/merge_interval.py Source
def merge_interval(low_priority_lst,high_priority_lst):</p>

<pre><code>'''
Given two lists with sorted date ranges, return merged list with high_priority_lst 
ranges preferred over low_priority_lst ranges in case of intersection.
Partial intervals are allowed.
'''
if low_priority_lst == [] or low_priority_lst == None: return high_priority_lst
if high_priority_lst == [] or high_priority_lst == None: return low_priority_lst

# case :               |-------|
#        |-------|            
if low_priority_lst[0][0] &gt; high_priority_lst[0][1]:
 return [high_priority_lst[0]] + 
        merge_interval(low_priority_lst,high_priority_lst[1:])
# case :   |-------|
#                     |-------|      
elif low_priority_lst[0][1] &lt; high_priority_lst[0][0]:
    return [low_priority_lst[0]] + 
        merge_interval(low_priority_lst[1:],high_priority_lst)
# case :|-------|
#            |-------|  
elif low_priority_lst[0][0] &lt; high_priority_lst[0][0]:
    return [[low_priority_lst[0][0],high_priority_lst[0][0]]] + 
        merge_interval( [[high_priority_lst[0][0],low_priority_lst[0][1]]] +
                             low_priority_lst[1:], high_priority_lst)
# case :      |-------|
#        |-------|  
elif low_priority_lst[0][1] &gt; high_priority_lst[0][1]:
    return [high_priority_lst[0]] + 
        merge_interval( [[high_priority_lst[0][1],low_priority_lst[0][1]]] +
                            low_priority_lst[1:] , high_priority_lst[1:])
# case :  |-------| |---| |----|
#        |-----------------| 
else:
    return merge_interval(low_priority_lst[1:],high_priority_lst)
</code></pre>

<p>```</p>

<p>Complexity :</p>

<!--more-->


<p>Analyzing time complexity for this gets interesting. Consider low_priority_lst to be of length l and high_priority_lst to be of length h. In the worst case each h interval is a sub interval of each l interval. That would give us a result set with 2*l + h elements and the thus the complexity of the algorithm is O(l+h) in the worst case.</p>

<p>Clearly this is not tail recursive, but as far as I know Python does not optimize for tail recursion. Something to think of is to extend it to lists 1...n, with priority p1 &lt; p2 &lt; .... pn, and which would give us a complexity of sum(si), 0&lt; i &lt; n-1 where si is the size of the ith interval.</p>

<p>If the lists are unsorted, adapting this method as is would require the caller method to sort the lists beforehand. Sorting being nlogn, it would dominate the linear compexity for and the complexity would be sum(si*log(si)), 0&lt; i &lt; n-1 for the case with n intervals.</p>
]]></content>
  </entry>
  
</feed>
